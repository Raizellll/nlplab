{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required libraries\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from datasets import Dataset\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "from rouge_score import rouge_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Qwen2.5-0.5B model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-0.5B\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen2.5-0.5B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. First define all helper functions\n",
    "def categorize_error(entity, entity_type):\n",
    "    \"\"\"分析错误类型\"\"\"\n",
    "    if len(entity) <= 1:\n",
    "        return 'short_entity'\n",
    "    elif any(title in entity for title in ['公', '王', '君', '尚', '太']):\n",
    "        return 'title_confusion'\n",
    "    elif entity_type == 'PER' and any(title in entity for title in ['令', '使', '官']):\n",
    "        return 'type_confusion'\n",
    "    elif len(entity.strip()) != len(entity):\n",
    "        return 'boundary_error'\n",
    "    return 'other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_ner_prompt(text):\n",
    "    return f\"\"\"请识别下面这段古文中的命名实体。\n",
    "\n",
    "示例输入1：\n",
    "\"太祖启曰：「朱五经平生读书」\"\n",
    "\n",
    "示例输出1：\n",
    "人名：\n",
    "太祖\n",
    "朱五经\n",
    "\n",
    "地名：\n",
    "\n",
    "官职：\n",
    "\n",
    "示例输入2：\n",
    "\"尚书天下尚书，岂独段家尚书也！\"\n",
    "\n",
    "示例输出2：\n",
    "人名：\n",
    "段家\n",
    "\n",
    "地名：\n",
    "\n",
    "官职：\n",
    "尚书\n",
    "\n",
    "注意事项：\n",
    "1. 每个实体独立成行\n",
    "2. 实体边界要准确，不要包含多余的称谓词\n",
    "3. 官职和人名要严格区分\n",
    "4. 如果某类没有实体，该类别下不需要填写任何内容\n",
    "\n",
    "现在请识别这段古文中的实体：\n",
    "{text}\n",
    "\n",
    "请按相同格式输出实体：\n",
    "\n",
    "人名：\n",
    "\n",
    "地名：\n",
    "\n",
    "官职：\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_summary_prompt(article):\n",
    "    return f\"\"\"请为以下新闻文章生成简短的摘要：\n",
    "\n",
    "文章：{article}\n",
    "\n",
    "摘要要求：\n",
    "1. 保留文章的主要信息\n",
    "2. 简明扼要\n",
    "3. 语言通顺自然\n",
    "\n",
    "请生成摘要：\"\"\"\n",
    "\n",
    "def evaluate_summary(prediction, reference):\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2'], use_stemmer=True)\n",
    "    scores = scorer.score(prediction, reference)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Both `max_new_tokens` (=2048) and `max_length`(=200) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "请识别下面这段古文中的命名实体。\n",
      "\n",
      "示例输入1：\n",
      "\"太祖启曰：「朱五经平生读书」\"\n",
      "\n",
      "示例输出1：\n",
      "人名：\n",
      "太祖\n",
      "朱五经\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "\n",
      "示例输入2：\n",
      "\"尚书天下尚书，岂独段家尚书也！\"\n",
      "\n",
      "示例输出2：\n",
      "人名：\n",
      "段家\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "尚书\n",
      "\n",
      "注意事项：\n",
      "1. 每个实体独立成行\n",
      "2. 实体边界要准确，不要包含多余的称谓词\n",
      "3. 官职和人名要严格区分\n",
      "4. 如果某类没有实体，该类别下不需要填写任何内容\n",
      "\n",
      "现在请识别这段古文中的实体：\n",
      "初在缙云山，太极真人徐君降之曰\n",
      "\n",
      "请按相同格式输出实体：\n",
      "\n",
      "人名：\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "太极真人\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "徐君\n",
      "\n",
      "地名\n"
     ]
    }
   ],
   "source": [
    "# 测试模型是否加载成功\n",
    "test_text = \"初在缙云山，太极真人徐君降之曰\"\n",
    "prompt = prepare_ner_prompt(test_text)\n",
    "\n",
    "# 生成回答\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "outputs = model.generate(**inputs, max_length=200)\n",
    "result = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "示例句子：\n",
      "文本: 或以问至德，荅曰：「夫庆赏刑罪，人主之权柄，凡为人臣，岂得与人主争权柄哉！」其慎密如此。后高宗知而深歎美之。仪凤四年薨，辍朝三日，使百官以次赴宅哭之，赠开府仪同三司、并州大都督，谥曰恭。\n",
      "标签: ['O', 'O', 'O', 'B-PER', 'E-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'E-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-OFI', 'I-OFI', 'I-OFI', 'I-OFI', 'I-OFI', 'E-OFI', 'O', 'B-LOC', 'E-LOC', 'B-OFI', 'I-OFI', 'E-OFI', 'O', 'O', 'O', 'S-PER', 'O']\n",
      "\n",
      "总句子数: 218\n"
     ]
    }
   ],
   "source": [
    "def load_ner_data(file_path):\n",
    "    sentences = []\n",
    "    current_sentence = []\n",
    "    current_tags = []\n",
    "    \n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line == '':  # 空行表示句子结束\n",
    "                if current_sentence:\n",
    "                    sentences.append({\n",
    "                        'text': ''.join(current_sentence),\n",
    "                        'tags': current_tags\n",
    "                    })\n",
    "                current_sentence = []\n",
    "                current_tags = []\n",
    "            else:\n",
    "                # 分割字符和标签\n",
    "                parts = line.split('\\t')\n",
    "                if len(parts) == 2:\n",
    "                    char, tag = parts\n",
    "                    current_sentence.append(char)\n",
    "                    current_tags.append(tag)\n",
    "    \n",
    "    # 处理最后一个句子\n",
    "    if current_sentence:\n",
    "        sentences.append({\n",
    "            'text': ''.join(current_sentence),\n",
    "            'tags': current_tags\n",
    "        })\n",
    "    \n",
    "    return sentences\n",
    "\n",
    "# 测试数据加载\n",
    "test_data = load_ner_data('data/ner.txt')\n",
    "\n",
    "# 打印一个示例句子\n",
    "if test_data:\n",
    "    print(\"示例句子：\")\n",
    "    print(\"文本:\", test_data[0]['text'])\n",
    "    print(\"标签:\", test_data[0]['tags'])\n",
    "    \n",
    "    # 统计数据集大小\n",
    "    print(f\"\\n总句子数: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "提取的实体：\n",
      "PER: ['至德', '高宗']\n",
      "LOC: ['并州']\n",
      "OFI: ['开府仪同三司', '大都督']\n"
     ]
    }
   ],
   "source": [
    "def extract_entities(text, tags):\n",
    "    entities = {\n",
    "        'PER': [],  # 人名\n",
    "        'LOC': [],  # 地名\n",
    "        'OFI': []   # 官职\n",
    "    }\n",
    "    \n",
    "    current_entity = ''\n",
    "    current_type = ''\n",
    "    \n",
    "    for char, tag in zip(text, tags):\n",
    "        if tag.startswith('B-'):  # 实体开始\n",
    "            if current_entity:  # 保存之前的实体\n",
    "                entities[current_type].append(current_entity)\n",
    "            current_type = tag[2:]  # 获取实体类型（PER/LOC/OFI）\n",
    "            current_entity = char\n",
    "        elif tag.startswith('I-') or tag.startswith('E-'):  # 实体中间或结束\n",
    "            current_entity += char\n",
    "        elif tag == 'O':  # 非实体\n",
    "            if current_entity:  # 保存之前的实体\n",
    "                entities[current_type].append(current_entity)\n",
    "                current_entity = ''\n",
    "                current_type = ''\n",
    "    \n",
    "    # 处理最后一个实体\n",
    "    if current_entity:\n",
    "        entities[current_type].append(current_entity)\n",
    "    \n",
    "    return entities\n",
    "\n",
    "# 测试实体提取\n",
    "if test_data:\n",
    "    sample = test_data[0]\n",
    "    entities = extract_entities(sample['text'], sample['tags'])\n",
    "    print(\"\\n提取的实体：\")\n",
    "    for entity_type, entity_list in entities.items():\n",
    "        print(f\"{entity_type}: {entity_list}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_predictions(text, max_retries=3):\n",
    "    prompt = prepare_ner_prompt(text)\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "            outputs = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=128,\n",
    "                do_sample=True,\n",
    "                temperature=0.3,  # Lower temperature for more focused output\n",
    "                top_p=0.9,\n",
    "                pad_token_id=tokenizer.eos_token_id,\n",
    "                early_stopping=True,\n",
    "                no_repeat_ngram_size=3,\n",
    "                num_return_sequences=1\n",
    "            )\n",
    "            result = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "            \n",
    "            # Remove prompt part\n",
    "            result = result.split(\"请按相同格式输出实体：\")[-1].strip()\n",
    "            \n",
    "            # Verify output format\n",
    "            if \"人名：\" in result and \"地名：\" in result and \"官职：\" in result:\n",
    "                return result\n",
    "            else:\n",
    "                print(f\"Attempt {attempt + 1}: Invalid output format\")\n",
    "                continue\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Attempt {attempt + 1} failed: {e}\")\n",
    "            if attempt == max_retries - 1:\n",
    "                return \"\"\n",
    "            continue\n",
    "    \n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_model_output(output):\n",
    "    \"\"\"将模型输出解析为结构化的实体字典\"\"\"\n",
    "    entities = {\n",
    "        'PER': [],\n",
    "        'LOC': [],\n",
    "        'OFI': []\n",
    "    }\n",
    "    \n",
    "    current_type = None\n",
    "    lines = output.split('\\n')\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        \n",
    "        # Skip empty lines and template text\n",
    "        if not line or '[' in line or ']' in line or '注' in line:\n",
    "            continue\n",
    "            \n",
    "        # Identify entity type\n",
    "        if '人名：' in line:\n",
    "            current_type = 'PER'\n",
    "            continue\n",
    "        elif '地名：' in line:\n",
    "            current_type = 'LOC'\n",
    "            continue\n",
    "        elif '官职：' in line:\n",
    "            current_type = 'OFI'\n",
    "            continue\n",
    "            \n",
    "        # Add entity if not a category header\n",
    "        if current_type and not line.endswith('：'):\n",
    "            entity = line.strip('- 　').strip()\n",
    "            if entity and len(entity) > 0:\n",
    "                entities[current_type].append(entity)\n",
    "    \n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(predicted_entities, true_entities, text=None, tags=None, include_O=False):\n",
    "    \"\"\"Calculate precision, recall and F1 score for entity predictions\"\"\"\n",
    "    metrics = {}\n",
    "    \n",
    "    # Preprocess entities: standardize format\n",
    "    def standardize_entities(entities_dict):\n",
    "        return {\n",
    "            k: set(e.strip() for e in v if e.strip())\n",
    "            for k, v in entities_dict.items()\n",
    "        }\n",
    "    \n",
    "    pred_entities = standardize_entities(predicted_entities)\n",
    "    true_entities = standardize_entities(true_entities)\n",
    "    \n",
    "    # Entity types to evaluate\n",
    "    entity_types = ['PER', 'LOC', 'OFI']\n",
    "    if include_O and text is not None and tags is not None:\n",
    "        entity_types.append('O')\n",
    "        # Add non-entity words to O category\n",
    "        pred_entities['O'] = set(word for word in text if word not in \n",
    "                               [e for ents in pred_entities.values() for e in ents])\n",
    "        true_entities['O'] = set(word for word, tag in zip(text, tags) if tag == 'O')\n",
    "    \n",
    "    for entity_type in entity_types:\n",
    "        pred_set = pred_entities.get(entity_type, set())\n",
    "        true_set = true_entities.get(entity_type, set())\n",
    "        \n",
    "        tp = len(pred_set & true_set)\n",
    "        fp = len(pred_set - true_set)\n",
    "        fn = len(true_set - pred_set)\n",
    "        \n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        \n",
    "        metrics[entity_type] = {\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1': f1\n",
    "        }\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_batch(test_data, num_samples=None):\n",
    "    \"\"\"Evaluate multiple samples in batch\"\"\"\n",
    "    if num_samples is None:\n",
    "        num_samples = len(test_data)\n",
    "    \n",
    "    results = {\n",
    "        'predictions': [],\n",
    "        'ground_truth': [],\n",
    "        'metrics_without_O': {\n",
    "            'PER': {'precision': [], 'recall': [], 'f1': []},\n",
    "            'LOC': {'precision': [], 'recall': [], 'f1': []},\n",
    "            'OFI': {'precision': [], 'recall': [], 'f1': []}\n",
    "        },\n",
    "        'metrics_with_O': {\n",
    "            'PER': {'precision': [], 'recall': [], 'f1': []},\n",
    "            'LOC': {'precision': [], 'recall': [], 'f1': []},\n",
    "            'OFI': {'precision': [], 'recall': [], 'f1': []},\n",
    "            'O': {'precision': [], 'recall': [], 'f1': []}\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    for i, sample in enumerate(test_data[:num_samples]):\n",
    "        print(f\"\\n处理样本 {i+1}/{num_samples}\")\n",
    "        \n",
    "        try:\n",
    "            # Get predictions and true labels\n",
    "            prediction = get_model_predictions(sample['text'])\n",
    "            if not prediction:\n",
    "                print(f\"样本 {i+1} 预测结果为空，跳过\")\n",
    "                continue\n",
    "                \n",
    "            parsed_prediction = parse_model_output(prediction)\n",
    "            true_entities = extract_entities(sample['text'], sample['tags'])\n",
    "            \n",
    "            # Store results\n",
    "            results['predictions'].append(parsed_prediction)\n",
    "            results['ground_truth'].append(true_entities)\n",
    "            \n",
    "            # Calculate metrics without O labels\n",
    "            metrics_without_O = calculate_metrics(\n",
    "                parsed_prediction, \n",
    "                true_entities,\n",
    "                include_O=False\n",
    "            )\n",
    "            \n",
    "            # Calculate metrics with O labels\n",
    "            metrics_with_O = calculate_metrics(\n",
    "                parsed_prediction,\n",
    "                true_entities,\n",
    "                text=sample['text'],\n",
    "                tags=sample['tags'],\n",
    "                include_O=True\n",
    "            )\n",
    "            \n",
    "            # Collect both types of metrics\n",
    "            for entity_type in metrics_without_O:\n",
    "                for metric in ['precision', 'recall', 'f1']:\n",
    "                    if entity_type in results['metrics_without_O']:\n",
    "                        results['metrics_without_O'][entity_type][metric].append(\n",
    "                            metrics_without_O[entity_type][metric]\n",
    "                        )\n",
    "            \n",
    "            for entity_type in metrics_with_O:\n",
    "                for metric in ['precision', 'recall', 'f1']:\n",
    "                    if entity_type in results['metrics_with_O']:\n",
    "                        results['metrics_with_O'][entity_type][metric].append(\n",
    "                            metrics_with_O[entity_type][metric]\n",
    "                        )\n",
    "            \n",
    "            print(f\"\\n样本 {i+1} 结果:\")\n",
    "            print(\"文本:\", sample['text'])\n",
    "            print(\"预测:\", parsed_prediction)\n",
    "            print(\"真实:\", true_entities)\n",
    "            print(\"不含O标签指标:\", metrics_without_O)\n",
    "            print(\"含O标签指标:\", metrics_with_O)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"处理样本 {i+1} 时发生错误: {e}\")\n",
    "            continue\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_single_sample(text, true_tags=None):\n",
    "    \"\"\"测试单个样本的实体识别效果\"\"\"\n",
    "    print(\"输入文本:\", text)\n",
    "    print(\"\\n生成的prompt:\")\n",
    "    print(prepare_ner_prompt(text))\n",
    "    \n",
    "    print(\"\\n模型输出:\")\n",
    "    prediction = get_model_predictions(text)\n",
    "    print(prediction)\n",
    "    \n",
    "    print(\"\\n解析后的实体:\")\n",
    "    parsed_entities = parse_model_output(prediction)\n",
    "    print(parsed_entities)\n",
    "    \n",
    "    if true_tags is not None:\n",
    "        print(\"\\n真实实体:\")\n",
    "        true_entities = extract_entities(text, true_tags)\n",
    "        print(true_entities)\n",
    "        \n",
    "        print(\"\\n评估指标:\")\n",
    "        metrics = calculate_metrics(parsed_entities, true_entities)\n",
    "        for entity_type, scores in metrics.items():\n",
    "            print(f\"{entity_type}:\", scores)\n",
    "    \n",
    "    return parsed_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ner_experiment(test_data, num_samples=None):\n",
    "    \"\"\"运行NER实验并记录结果\"\"\"\n",
    "    print(\"开始NER实验...\")\n",
    "    print(f\"数据集大小: {len(test_data)} 样本\")\n",
    "    print(f\"实际使用样本数: {num_samples if num_samples else len(test_data)}\")\n",
    "    \n",
    "    try:\n",
    "        # 1. 单样本测试\n",
    "        print(\"\\n1. 单样本测试\")\n",
    "        print(\"-\" * 50)\n",
    "        sample = test_data[0]\n",
    "        test_single_sample(sample['text'], sample['tags'])\n",
    "        \n",
    "        # 2. 批量评估\n",
    "        print(\"\\n2. 批量评估\")\n",
    "        print(\"-\" * 50)\n",
    "        results = evaluate_batch(test_data, num_samples)\n",
    "        \n",
    "        # 3. 打印总体结果\n",
    "        print(\"\\n3. 实验结果总结\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        # 计算并打印平均指标\n",
    "        for metric_type in ['metrics_without_O', 'metrics_with_O']:\n",
    "            print(f\"\\n{metric_type}:\")\n",
    "            for entity_type in results[metric_type]:\n",
    "                metrics = results[metric_type][entity_type]\n",
    "                try:\n",
    "                    avg_metrics = {\n",
    "                        k: np.mean(v) if v else 0.0 \n",
    "                        for k, v in metrics.items()\n",
    "                    }\n",
    "                    print(f\"\\n{entity_type}类实体:\")\n",
    "                    print(f\"Precision: {avg_metrics['precision']:.4f}\")\n",
    "                    print(f\"Recall: {avg_metrics['recall']:.4f}\")\n",
    "                    print(f\"F1: {avg_metrics['f1']:.4f}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"计算{entity_type}指标时出错: {e}\")\n",
    "                    continue\n",
    "        \n",
    "        # 4. 错误分析\n",
    "        print(\"\\n4. 错误分析示例\")\n",
    "        print(\"-\" * 50)\n",
    "        analyze_errors(results, n_examples=3)\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"实验运行出错: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_macro_f1(results):\n",
    "    \"\"\"Calculate macro F1 score across all entity types\"\"\"\n",
    "    entity_types = ['PER', 'LOC', 'OFI']\n",
    "    f1_scores = []\n",
    "    \n",
    "    # Calculate F1 for each entity type\n",
    "    for entity_type in entity_types:\n",
    "        type_metrics = results['metrics_without_O'][entity_type]\n",
    "        if type_metrics['f1']:  # Only include if we have scores\n",
    "            avg_f1 = sum(type_metrics['f1']) / len(type_metrics['f1'])\n",
    "            f1_scores.append(avg_f1)\n",
    "    \n",
    "    # Calculate macro F1\n",
    "    macro_f1 = sum(f1_scores) / len(f1_scores) if f1_scores else 0\n",
    "    \n",
    "    return macro_f1\n",
    "\n",
    "def analyze_errors(results, n_examples=3):\n",
    "    \"\"\"Enhanced error analysis with categorization\"\"\"\n",
    "    error_stats = {\n",
    "        'PER': {'false_positives': 0, 'false_negatives': 0, 'boundary_errors': 0},\n",
    "        'LOC': {'false_positives': 0, 'false_negatives': 0, 'boundary_errors': 0},\n",
    "        'OFI': {'false_positives': 0, 'false_negatives': 0, 'boundary_errors': 0}\n",
    "    }\n",
    "    \n",
    "    error_categories = {\n",
    "        'boundary_issues': 0,\n",
    "        'title_confusion': 0,\n",
    "        'missing_short_entities': 0,\n",
    "        'wrong_entity_type': 0,\n",
    "        'other': 0\n",
    "    }\n",
    "    \n",
    "    print(\"详细错误分析:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for i, (pred, true) in enumerate(zip(results['predictions'], results['ground_truth'])):\n",
    "        if i >= n_examples:\n",
    "            break\n",
    "            \n",
    "        print(f\"\\n示例 {i+1}:\")\n",
    "        for entity_type in ['PER', 'LOC', 'OFI']:\n",
    "            pred_set = set(pred.get(entity_type, []))\n",
    "            true_set = set(true.get(entity_type, []))\n",
    "            \n",
    "            false_positives = pred_set - true_set\n",
    "            false_negatives = true_set - pred_set\n",
    "            \n",
    "            # Analyze error types\n",
    "            for entity in false_positives:\n",
    "                error_type = categorize_error(entity, entity_type)\n",
    "                error_categories[error_type] += 1\n",
    "                \n",
    "            error_stats[entity_type]['false_positives'] += len(false_positives)\n",
    "            error_stats[entity_type]['false_negatives'] += len(false_negatives)\n",
    "            \n",
    "            if false_positives or false_negatives:\n",
    "                print(f\"\\n{entity_type} 类实体错误:\")\n",
    "                if false_positives:\n",
    "                    print(f\"错误预测: {false_positives}\")\n",
    "                if false_negatives:\n",
    "                    print(f\"漏检: {false_negatives}\")\n",
    "    \n",
    "    # Calculate macro F1\n",
    "    macro_f1 = calculate_macro_f1(results)\n",
    "    \n",
    "    print(\"\\n总体性能指标:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"宏平均F1分数: {macro_f1:.4f}\")\n",
    "    \n",
    "    print(\"\\n错误类型统计:\")\n",
    "    print(\"-\" * 50)\n",
    "    for category, count in error_categories.items():\n",
    "        print(f\"{category}: {count} 次\")\n",
    "    \n",
    "    return error_stats, error_categories, macro_f1\n",
    "\n",
    "def analyze_error_cause(entities, entity_type):\n",
    "    \"\"\"分析错误可能的原因\"\"\"\n",
    "    causes = []\n",
    "    \n",
    "    for entity in entities:\n",
    "        if len(entity) <= 1:\n",
    "            causes.append(\"实体边界识别不准确\")\n",
    "        if entity_type == 'PER' and ('公' in entity or '王' in entity):\n",
    "            causes.append(\"称谓词被错误包含在人名中\")\n",
    "        if entity_type == 'OFI' and len(entity) > 4:\n",
    "            causes.append(\"官职边界过长\")\n",
    "            \n",
    "    return list(set(causes)) if causes else [\"需要更多训练样例\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_summary_report(results):\n",
    "    \"\"\"Print a comprehensive summary report\"\"\"\n",
    "    error_stats, error_categories, macro_f1 = analyze_errors(results)\n",
    "    \n",
    "    print(\"\\n=== 性能评估报告 ===\")\n",
    "    print(\"\\n1. 总体性能:\")\n",
    "    print(f\"宏平均F1分数: {macro_f1:.4f}\")\n",
    "    \n",
    "    print(\"\\n2. 各实体类型性能:\")\n",
    "    for entity_type in ['PER', 'LOC', 'OFI']:\n",
    "        metrics = results['metrics_without_O'][entity_type]\n",
    "        avg_precision = sum(metrics['precision']) / len(metrics['precision']) if metrics['precision'] else 0\n",
    "        avg_recall = sum(metrics['recall']) / len(metrics['recall']) if metrics['recall'] else 0\n",
    "        avg_f1 = sum(metrics['f1']) / len(metrics['f1']) if metrics['f1'] else 0\n",
    "        \n",
    "        print(f\"\\n{entity_type}:\")\n",
    "        print(f\"精确率: {avg_precision:.4f}\")\n",
    "        print(f\"召回率: {avg_recall:.4f}\")\n",
    "        print(f\"F1分数: {avg_f1:.4f}\")\n",
    "    \n",
    "    print(\"\\n3. 主要错误类型:\")\n",
    "    for category, count in error_categories.items():\n",
    "        print(f\"{category}: {count} 次\")\n",
    "    \n",
    "    print(\"\\n4. 改进建议:\")\n",
    "    print(\"- 加强实体边界识别\")\n",
    "    print(\"- 改进称谓词处理规则\")\n",
    "    print(\"- 增加短实体的识别准确率\")\n",
    "    print(\"- 优化实体类型分类\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "小批量测试:\n",
      "开始NER实验...\n",
      "数据集大小: 218 样本\n",
      "实际使用样本数: 5\n",
      "\n",
      "1. 单样本测试\n",
      "--------------------------------------------------\n",
      "输入文本: 或以问至德，荅曰：「夫庆赏刑罪，人主之权柄，凡为人臣，岂得与人主争权柄哉！」其慎密如此。后高宗知而深歎美之。仪凤四年薨，辍朝三日，使百官以次赴宅哭之，赠开府仪同三司、并州大都督，谥曰恭。\n",
      "\n",
      "生成的prompt:\n",
      "请识别下面这段古文中的命名实体。\n",
      "\n",
      "示例输入1：\n",
      "\"太祖启曰：「朱五经平生读书」\"\n",
      "\n",
      "示例输出1：\n",
      "人名：\n",
      "太祖\n",
      "朱五经\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "\n",
      "示例输入2：\n",
      "\"尚书天下尚书，岂独段家尚书也！\"\n",
      "\n",
      "示例输出2：\n",
      "人名：\n",
      "段家\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "尚书\n",
      "\n",
      "注意事项：\n",
      "1. 每个实体独立成行\n",
      "2. 实体边界要准确，不要包含多余的称谓词\n",
      "3. 官职和人名要严格区分\n",
      "4. 如果某类没有实体，该类别下不需要填写任何内容\n",
      "\n",
      "现在请识别这段古文中的实体：\n",
      "或以问至德，荅曰：「夫庆赏刑罪，人主之权柄，凡为人臣，岂得与人主争权柄哉！」其慎密如此。后高宗知而深歎美之。仪凤四年薨，辍朝三日，使百官以次赴宅哭之，赠开府仪同三司、并州大都督，谥曰恭。\n",
      "\n",
      "请按相同格式输出实体：\n",
      "\n",
      "人名：\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "\n",
      "\n",
      "模型输出:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "人名：\n",
      "\n",
      "地名：\n",
      "\n",
      "官职：\n",
      "仪凤\n",
      "\n",
      "地官职：仪凤\n",
      "高宗\n",
      "知\n",
      "高\n",
      "仪凤\n",
      "\n",
      "解析后的实体:\n",
      "{'PER': [], 'LOC': [], 'OFI': ['仪凤', '高宗', '知', '高', '仪凤']}\n",
      "\n",
      "真实实体:\n",
      "{'PER': ['至德', '高宗'], 'LOC': ['并州'], 'OFI': ['开府仪同三司', '大都督']}\n",
      "\n",
      "评估指标:\n",
      "PER: {'precision': 0, 'recall': 0.0, 'f1': 0}\n",
      "LOC: {'precision': 0, 'recall': 0.0, 'f1': 0}\n",
      "OFI: {'precision': 0.0, 'recall': 0.0, 'f1': 0}\n",
      "\n",
      "2. 批量评估\n",
      "--------------------------------------------------\n",
      "\n",
      "处理样本 1/5\n",
      "\n",
      "样本 1 结果:\n",
      "文本: 或以问至德，荅曰：「夫庆赏刑罪，人主之权柄，凡为人臣，岂得与人主争权柄哉！」其慎密如此。后高宗知而深歎美之。仪凤四年薨，辍朝三日，使百官以次赴宅哭之，赠开府仪同三司、并州大都督，谥曰恭。\n",
      "预测: {'PER': [], 'LOC': [], 'OFI': ['仪凤', '地官员职：仪同', '地员官职', '仪凤', '开府', '仪同', '并州', '大都', '州', '都督', '谥', '或问至徳，荘曰：夫庆賞刑罪人主權柄凡为人子，不得與人主爭權柄也！其慎明如此。後高宗深歊美之。', '或', '问', '至徧', '荅', '曰', '夫', '慶賞', '刑罪', '人主', '權柄', '凡', '為']}\n",
      "真实: {'PER': ['至德', '高宗'], 'LOC': ['并州'], 'OFI': ['开府仪同三司', '大都督']}\n",
      "不含O标签指标: {'PER': {'precision': 0, 'recall': 0.0, 'f1': 0}, 'LOC': {'precision': 0, 'recall': 0.0, 'f1': 0}, 'OFI': {'precision': 0.0, 'recall': 0.0, 'f1': 0}}\n",
      "含O标签指标: {'PER': {'precision': 0, 'recall': 0.0, 'f1': 0}, 'LOC': {'precision': 0, 'recall': 0.0, 'f1': 0}, 'OFI': {'precision': 0.0, 'recall': 0.0, 'f1': 0}, 'O': {'precision': 0.8, 'recall': 0.8813559322033898, 'f1': 0.8387096774193548}}\n",
      "\n",
      "处理样本 2/5\n",
      "\n",
      "样本 2 结果:\n",
      "文本: 宣帝即位，授上柱国。运之为宫正也，数进谏于帝。帝不纳，反疏忌之。时运又与王轨、宇文孝伯等皆为武帝亲待。\n",
      "预测: {'PER': [], 'LOC': [], 'OFI': ['宣', '帝', '即位', '授', '上', '柱国', '运', '为', '宫', '正', '也', '数', '进', '谏', '于', '帝', '地', '宣', '官', '帝', '就', '位', '，', '授上', '，', '柱', '国', '。', '运', '之', '为宫', '，', '正', '。', '数', '入', '谏于', '，', '帝', '不', '纳，', '反疏', '，', '忌', '之。', '时运', '又', '与', '王', '轨', '、', '宇文', '孝伯', '等', '皆', '为武', '帝亲', '待。', '现在请按']}\n",
      "真实: {'PER': ['宣帝', '王轨', '宇文孝伯', '武帝'], 'LOC': [], 'OFI': ['上柱国', '宫正']}\n",
      "不含O标签指标: {'PER': {'precision': 0, 'recall': 0.0, 'f1': 0}, 'LOC': {'precision': 0, 'recall': 0, 'f1': 0}, 'OFI': {'precision': 0.0, 'recall': 0.0, 'f1': 0}}\n",
      "含O标签指标: {'PER': {'precision': 0, 'recall': 0.0, 'f1': 0}, 'LOC': {'precision': 0, 'recall': 0, 'f1': 0}, 'OFI': {'precision': 0.0, 'recall': 0.0, 'f1': 0}, 'O': {'precision': 0.5833333333333334, 'recall': 0.2692307692307692, 'f1': 0.3684210526315789}}\n",
      "\n",
      "处理样本 3/5\n",
      "\n",
      "样本 3 结果:\n",
      "文本: 阿剌怗木儿袭职，授虎符，緫管高丽人户。至元八年，将兵讨叛贼金通精，贼败走耽罗。十一年，进昭勇大将军，从都元帅忽都征日本国，预有战功。\n",
      "预测: {'PER': [], 'LOC': [], 'OFI': ['阿刺怗', '木儿', '袭职', '授', '虎符', '緫', '管', '高丽', '人户', '至元', '八年', '将', '兵', '讨', '叛', '贼', '金通', '精', '贼败', '走', '耽罗', '十一年', '进', '昭勇', '大将军', '从', '都元', '帅', '忽都', '征', '日本', '国', '预', '有', '战', '功', '阿', '剌', '怗', '示', '木', '儿', '襲', '职', '授', '老虎', '符', '授']}\n",
      "真实: {'PER': ['阿剌怗木儿', '金通精', '忽都'], 'LOC': ['高丽', '耽罗', '日本国'], 'OFI': ['昭勇大将军', '都元帅']}\n",
      "不含O标签指标: {'PER': {'precision': 0, 'recall': 0.0, 'f1': 0}, 'LOC': {'precision': 0, 'recall': 0.0, 'f1': 0}, 'OFI': {'precision': 0.0, 'recall': 0.0, 'f1': 0}}\n",
      "含O标签指标: {'PER': {'precision': 0, 'recall': 0.0, 'f1': 0}, 'LOC': {'precision': 0, 'recall': 0.0, 'f1': 0}, 'OFI': {'precision': 0.0, 'recall': 0.0, 'f1': 0}, 'O': {'precision': 0.48148148148148145, 'recall': 0.41935483870967744, 'f1': 0.4482758620689655}}\n",
      "\n",
      "处理样本 4/5\n",
      "\n",
      "样本 4 结果:\n",
      "文本: 孝武西迁，进车骑大将军、仪同三司，别封万年县伯，乃除华州刺史。齐神武率军进潼关，人怀危惧，罴劝励将士，众心乃安。\n",
      "预测: {'PER': [], 'LOC': [], 'OFI': ['孝', '武', '西迁', '进', '车骑', '大', '将军', '仪同', '三', '司', '别', '封', '万年', '县', '伯', '乃', '除', '华', '州', '刺', '史', '齐', '神', '武', '潼关', '罴']}\n",
      "真实: {'PER': ['孝武', '神武'], 'LOC': ['华州', '潼关'], 'OFI': ['车骑大将军', '仪同三司', '万年县伯', '刺史']}\n",
      "不含O标签指标: {'PER': {'precision': 0, 'recall': 0.0, 'f1': 0}, 'LOC': {'precision': 0, 'recall': 0.0, 'f1': 0}, 'OFI': {'precision': 0.0, 'recall': 0.0, 'f1': 0}}\n",
      "含O标签指标: {'PER': {'precision': 0, 'recall': 0.0, 'f1': 0}, 'LOC': {'precision': 0, 'recall': 0.0, 'f1': 0}, 'OFI': {'precision': 0.0, 'recall': 0.0, 'f1': 0}, 'O': {'precision': 0.6923076923076923, 'recall': 0.75, 'f1': 0.7199999999999999}}\n",
      "\n",
      "处理样本 5/5\n",
      "\n",
      "样本 5 结果:\n",
      "文本: 子智袭职，授三珠虎符、宣武将军，为万户。延祐二年，进明威将军，以病去职。子安世袭。\n",
      "预测: {'PER': [], 'LOC': [], 'OFI': ['子', '智', '袭', '职', '授', '三', '珠', '虎', '符', '宣', '武', '将军', '，为', '万户', '。', '授：职', '三珠：虎符', '符：宣武', '军：将军', '为：万户', '人名:', '子', '官名:', '智', '地', '名:', '袭', '官', '职:', '袭', '人 名:', '子', '地 名:', '智', '官 名:', '袭']}\n",
      "真实: {'PER': [], 'LOC': [], 'OFI': ['宣武将军', '万户', '明威将军']}\n",
      "不含O标签指标: {'PER': {'precision': 0, 'recall': 0, 'f1': 0}, 'LOC': {'precision': 0, 'recall': 0, 'f1': 0}, 'OFI': {'precision': 0.034482758620689655, 'recall': 0.3333333333333333, 'f1': 0.0625}}\n",
      "含O标签指标: {'PER': {'precision': 0, 'recall': 0, 'f1': 0}, 'LOC': {'precision': 0, 'recall': 0, 'f1': 0}, 'OFI': {'precision': 0.034482758620689655, 'recall': 0.3333333333333333, 'f1': 0.0625}, 'O': {'precision': 0.631578947368421, 'recall': 0.5714285714285714, 'f1': 0.6}}\n",
      "\n",
      "3. 实验结果总结\n",
      "--------------------------------------------------\n",
      "\n",
      "metrics_without_O:\n",
      "\n",
      "PER类实体:\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1: 0.0000\n",
      "\n",
      "LOC类实体:\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1: 0.0000\n",
      "\n",
      "OFI类实体:\n",
      "Precision: 0.0069\n",
      "Recall: 0.0667\n",
      "F1: 0.0125\n",
      "\n",
      "metrics_with_O:\n",
      "\n",
      "PER类实体:\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1: 0.0000\n",
      "\n",
      "LOC类实体:\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1: 0.0000\n",
      "\n",
      "OFI类实体:\n",
      "Precision: 0.0069\n",
      "Recall: 0.0667\n",
      "F1: 0.0125\n",
      "\n",
      "O类实体:\n",
      "Precision: 0.6377\n",
      "Recall: 0.5783\n",
      "F1: 0.5951\n",
      "\n",
      "4. 错误分析示例\n",
      "--------------------------------------------------\n",
      "详细错误分析:\n",
      "--------------------------------------------------\n",
      "\n",
      "示例 1:\n",
      "\n",
      "PER 类实体错误:\n",
      "漏检: {'至德', '高宗'}\n",
      "\n",
      "LOC 类实体错误:\n",
      "漏检: {'并州'}\n",
      "实验运行出错: name 'categorize_error' is not defined\n"
     ]
    }
   ],
   "source": [
    "# 先用小批量数据测试\n",
    "print(\"小批量测试:\")\n",
    "results = run_ner_experiment(test_data, num_samples=5)\n",
    "\n",
    "# 如果一切正常，运行完整实验\n",
    "# print(\"\\n完整实验:\")\n",
    "# full_metrics, full_results = run_ner_experiment(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compare_methods(llm_metrics, traditional_metrics):\n",
    "#     \"\"\"对比LLM方法和传统方法的性能\"\"\"\n",
    "#     print(\"性能对比分析:\")\n",
    "#     print(\"-\" * 50)\n",
    "    \n",
    "#     for entity_type in ['PER', 'LOC', 'OFI']:\n",
    "#         print(f\"\\n{entity_type} 类实体:\")\n",
    "#         print(\"指标\\t\\tLLM方法\\t传统方法\\t差异\")\n",
    "#         print(\"-\" * 50)\n",
    "        \n",
    "#         for metric in ['precision', 'recall', 'f1']:\n",
    "#             llm_score = llm_metrics[entity_type][metric]\n",
    "#             trad_score = traditional_metrics[entity_type][metric]\n",
    "#             diff = llm_score - trad_score\n",
    "            \n",
    "#             print(f\"{metric}\\t\\t{llm_score:.4f}\\t{trad_score:.4f}\\t{diff:+.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
